This project focuses on training a YOLO (You Only Look Once) object detection model using a custom-labeled dataset, and then applying the trained model to automatically label a separate set of unlabeled images located in the `raw_unlabeled` folder. The dataset is structured with labeled images and annotations placed in `images/train` directory, and configured via a `data.yaml` file. After training the model and obtaining the best weights, inference is performed on the unlabeled images to generate YOLO-format label files, enabling their potential inclusion in the training set to improve model performance through iterative retraining.
